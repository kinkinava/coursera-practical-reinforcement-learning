{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sarsa.ipynb",
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tva_4FFJnIM5"
      },
      "source": [
        "## On-policy learning and SARSA\n",
        "\n",
        "_This notebook builds upon `qlearning.ipynb`, or to be exact your implementation of QLearningAgent._\n",
        "\n",
        "The policy we're gonna use is epsilon-greedy policy, where agent takes optimal action with probability $(1-\\epsilon)$, otherwise samples action at random. Note that agent __can__ occasionally sample optimal action during random sampling by pure chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzfMic3TnIM8"
      },
      "source": [
        "import sys, os\n",
        "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
        "\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/grading.py -O ../grading.py\n",
        "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/coursera/week3_model_free/submit.py\n",
        "\n",
        "    !touch .setup_complete\n",
        "\n",
        "# This code creates a virtual display to draw game images on.\n",
        "# It will have no effect if your machine has a monitor.\n",
        "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
        "    !bash ../xvfb start\n",
        "    os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLCVOYVXnIM9"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcFbI3g2nIM-"
      },
      "source": [
        "You can copy your `QLearningAgent` implementation from previous notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sD5Zbb8bnIM-"
      },
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class QLearningAgent:\n",
        "    def __init__(self, alpha, epsilon, discount, get_legal_actions):\n",
        "        \"\"\"\n",
        "        Q-Learning Agent\n",
        "        based on https://inst.eecs.berkeley.edu/~cs188/sp19/projects.html\n",
        "        Instance variables you have access to\n",
        "          - self.epsilon (exploration prob)\n",
        "          - self.alpha (learning rate)\n",
        "          - self.discount (discount rate aka gamma)\n",
        "\n",
        "        Functions you should use\n",
        "          - self.get_legal_actions(state) {state, hashable -> list of actions, each is hashable}\n",
        "            which returns legal actions for a state\n",
        "          - self.get_qvalue(state,action)\n",
        "            which returns Q(state,action)\n",
        "          - self.set_qvalue(state,action,value)\n",
        "            which sets Q(state,action) := value\n",
        "        !!!Important!!!\n",
        "        Note: please avoid using self._qValues directly. \n",
        "            There's a special self.get_qvalue/set_qvalue for that.\n",
        "        \"\"\"\n",
        "\n",
        "        self.get_legal_actions = get_legal_actions\n",
        "        self._qvalues = defaultdict(lambda: defaultdict(lambda: 0))\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "        self.discount = discount\n",
        "\n",
        "    def get_qvalue(self, state, action):\n",
        "        \"\"\" Returns Q(state,action) \"\"\"\n",
        "        return self._qvalues[state][action]\n",
        "\n",
        "    def set_qvalue(self, state, action, value):\n",
        "        \"\"\" Sets the Qvalue for [state,action] to the given value \"\"\"\n",
        "        self._qvalues[state][action] = value\n",
        "\n",
        "    #---------------------START OF YOUR CODE---------------------#\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\"\n",
        "        Compute your agent's estimate of V(s) using current q-values\n",
        "        V(s) = max_over_action Q(state,action) over possible actions.\n",
        "        Note: please take into account that q-values can be negative.\n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "        value = -9999999999999\n",
        "        for action in possible_actions:\n",
        "          if (value < self.get_qvalue(state,action)):\n",
        "            value = self.get_qvalue(state,action)\n",
        "\n",
        "        return value\n",
        "\n",
        "    def update(self, state, action, reward, next_state):\n",
        "        \"\"\"\n",
        "        You should do your Q-Value update here:\n",
        "           Q(s,a) := (1 - alpha) * Q(s,a) + alpha * (r + gamma * V(s'))\n",
        "        \"\"\"\n",
        "\n",
        "        # agent parameters\n",
        "        gamma = self.discount\n",
        "        learning_rate = self.alpha\n",
        "\n",
        "        qValue = (1- learning_rate) * self.get_qvalue(state,action) + learning_rate * (reward + gamma * self.get_value(next_state))\n",
        "\n",
        "        self.set_qvalue(state, action, qValue )\n",
        "\n",
        "    def get_best_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the best action to take in a state (using current q-values). \n",
        "        \"\"\"\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        max = -999999999999\n",
        "        best_action = 0\n",
        "        for action in possible_actions:\n",
        "          if (self.get_qvalue(state,action) > max):\n",
        "            best_action = action\n",
        "            max = self.get_qvalue(state,action)\n",
        " \n",
        "\n",
        "        return best_action\n",
        "\n",
        "    def get_action(self, state):\n",
        "        \"\"\"\n",
        "        Compute the action to take in the current state, including exploration.  \n",
        "        With probability self.epsilon, we should take a random action.\n",
        "            otherwise - the best policy action (self.get_best_action).\n",
        "\n",
        "        Note: To pick randomly from a list, use random.choice(list). \n",
        "              To pick True or False with a given probablity, generate uniform number in [0, 1]\n",
        "              and compare it with your probability\n",
        "        \"\"\"\n",
        "\n",
        "        # Pick Action\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "        action = None\n",
        "\n",
        "        # If there are no legal actions, return None\n",
        "        if len(possible_actions) == 0:\n",
        "            return None\n",
        "\n",
        "        # agent parameters:\n",
        "        epsilon = self.epsilon\n",
        "\n",
        "        if (np.random.uniform() <= epsilon):\n",
        "          chosen_action = random.choice(possible_actions)\n",
        "        else:\n",
        "          chosen_action = self.get_best_action(state)\n",
        "    \n",
        "        return chosen_action"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rk8V_4uNnIM_"
      },
      "source": [
        "Now we gonna implement Expected Value SARSA on top of it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9471y5ynINA"
      },
      "source": [
        "class EVSarsaAgent(QLearningAgent):\n",
        "    \"\"\" \n",
        "    An agent that changes some of q-learning functions to implement Expected Value SARSA. \n",
        "    Note: this demo assumes that your implementation of QLearningAgent.update uses get_value(next_state).\n",
        "    If it doesn't, please add\n",
        "        def update(self, state, action, reward, next_state):\n",
        "            and implement it for Expected Value SARSA's V(s')\n",
        "    \"\"\"\n",
        "\n",
        "    def get_value(self, state):\n",
        "        \"\"\" \n",
        "        Returns Vpi for current state under epsilon-greedy policy:\n",
        "          V_{pi}(s) = sum _{over a_i} {pi(a_i | s) * Q(s, a_i)}\n",
        "\n",
        "        Hint: all other methods from QLearningAgent are still accessible.\n",
        "        \"\"\"\n",
        "        epsilon = self.epsilon\n",
        "        possible_actions = self.get_legal_actions(state)\n",
        "\n",
        "\n",
        "\n",
        "        # If there are no legal actions, return 0.0\n",
        "        if len(possible_actions) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        state_value = 0\n",
        "        for action in possible_actions:\n",
        "          # Best action : epsilon / number of action\n",
        "          if (action == self.get_best_action(state)):\n",
        "            state_value += (1-epsilon +epsilon / len(possible_actions)  ) * self.get_qvalue(state,action)\n",
        "          else:\n",
        "            state_value += epsilon / len(possible_actions) *self.get_qvalue(state,action)\n",
        "\n",
        "        return state_value"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFEh_i26nINA"
      },
      "source": [
        "### Cliff World\n",
        "\n",
        "Let's now see how our algorithm compares against q-learning in case where we force agent to explore all the time.\n",
        "\n",
        "<img src=https://github.com/yandexdataschool/Practical_RL/raw/master/yet_another_week/_resource/cliffworld.png width=600>\n",
        "<center><i>image by cs188</i></center>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmBr1rF1nINB",
        "outputId": "fa4d5781-17aa-4e97-d265-4243620f44ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import gym\n",
        "import gym.envs.toy_text\n",
        "env = gym.envs.toy_text.CliffWalkingEnv()\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "print(env.__doc__)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    This is a simple implementation of the Gridworld Cliff\n",
            "    reinforcement learning task.\n",
            "\n",
            "    Adapted from Example 6.6 (page 106) from Reinforcement Learning: An Introduction\n",
            "    by Sutton and Barto:\n",
            "    http://incompleteideas.net/book/bookdraft2018jan1.pdf\n",
            "\n",
            "    With inspiration from:\n",
            "    https://github.com/dennybritz/reinforcement-learning/blob/master/lib/envs/cliff_walking.py\n",
            "\n",
            "    The board is a 4x12 matrix, with (using Numpy matrix indexing):\n",
            "        [3, 0] as the start at bottom-left\n",
            "        [3, 11] as the goal at bottom-right\n",
            "        [3, 1..10] as the cliff at bottom-center\n",
            "\n",
            "    Each time step incurs -1 reward, and stepping into the cliff incurs -100 reward\n",
            "    and a reset to the start. An episode terminates when the agent reaches the goal.\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUxLLKEOnINB",
        "outputId": "5384ef54-3457-4406-98d1-4eeebe4bffa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Our cliffworld has one difference from what's on the image: there is no wall.\n",
        "# Agent can choose to go as close to the cliff as it wishes. x:start, T:exit, C:cliff, o: flat ground\n",
        "env.render()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "o  o  o  o  o  o  o  o  o  o  o  o\n",
            "x  C  C  C  C  C  C  C  C  C  C  T\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BaY7TazgnINC"
      },
      "source": [
        "def play_and_train(env, agent, t_max=10**4):\n",
        "    \"\"\"This function should \n",
        "    - run a full game, actions given by agent.getAction(s)\n",
        "    - train agent using agent.update(...) whenever possible\n",
        "    - return total reward\"\"\"\n",
        "    total_reward = 0.0\n",
        "    s = env.reset()\n",
        "\n",
        "    for t in range(t_max):\n",
        "        a = agent.get_action(s)\n",
        "\n",
        "        next_s, r, done, _ = env.step(a)\n",
        "        agent.update(s, a, r, next_s)\n",
        "\n",
        "        s = next_s\n",
        "        total_reward += r\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "    return total_reward"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u85OtEEqnINC"
      },
      "source": [
        "agent_sarsa = EVSarsaAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                           get_legal_actions=lambda s: range(n_actions))\n",
        "\n",
        "agent_ql = QLearningAgent(alpha=0.25, epsilon=0.2, discount=0.99,\n",
        "                          get_legal_actions=lambda s: range(n_actions))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cPz3Ptt7nINC",
        "outputId": "cfb8fa39-526e-4827-f7ab-21adc2e16f0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "from IPython.display import clear_output\n",
        "import pandas as pd\n",
        "\n",
        "def moving_average(x, span=100):\n",
        "    return pd.DataFrame({'x': np.asarray(x)}).x.ewm(span=span).mean().values\n",
        "\n",
        "rewards_sarsa, rewards_ql = [], []\n",
        "\n",
        "for i in range(5000):\n",
        "    rewards_sarsa.append(play_and_train(env, agent_sarsa))\n",
        "    rewards_ql.append(play_and_train(env, agent_ql))\n",
        "    # Note: agent.epsilon stays constant\n",
        "\n",
        "    if i % 100 == 0:\n",
        "        clear_output(True)\n",
        "        print('EVSARSA mean reward =', np.mean(rewards_sarsa[-100:]))\n",
        "        print('QLEARNING mean reward =', np.mean(rewards_ql[-100:]))\n",
        "        plt.title(\"epsilon = %s\" % agent_ql.epsilon)\n",
        "        plt.plot(moving_average(rewards_sarsa), label='ev_sarsa')\n",
        "        plt.plot(moving_average(rewards_ql), label='qlearning')\n",
        "        plt.grid()\n",
        "        plt.legend()\n",
        "        plt.ylim(-500, 0)\n",
        "        plt.show()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EVSARSA mean reward = -25.88\n",
            "QLEARNING mean reward = -80.29\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSO91rDGnIND"
      },
      "source": [
        "Let's now see what did the algorithms learn by visualizing their actions at every state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gJP4XX-nIND"
      },
      "source": [
        "def draw_policy(env, agent):\n",
        "    \"\"\" Prints CliffWalkingEnv policy with arrows. Hard-coded. \"\"\"\n",
        "    n_rows, n_cols = env._cliff.shape\n",
        "\n",
        "    actions = '^>v<'\n",
        "\n",
        "    for yi in range(n_rows):\n",
        "        for xi in range(n_cols):\n",
        "            if env._cliff[yi, xi]:\n",
        "                print(\" C \", end='')\n",
        "            elif (yi * n_cols + xi) == env.start_state_index:\n",
        "                print(\" X \", end='')\n",
        "            elif (yi * n_cols + xi) == n_rows * n_cols - 1:\n",
        "                print(\" T \", end='')\n",
        "            else:\n",
        "                print(\" %s \" %\n",
        "                      actions[agent.get_best_action(yi * n_cols + xi)], end='')\n",
        "        print()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKtamSA-nIND",
        "outputId": "1178f6d4-c169-4aa6-a683-daa868d8a521",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"Q-Learning\")\n",
        "draw_policy(env, agent_ql)\n",
        "\n",
        "print(\"SARSA\")\n",
        "draw_policy(env, agent_sarsa)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Learning\n",
            " >  >  v  v  v  v  v  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n",
            "SARSA\n",
            " >  >  >  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  >  >  >  >  >  >  >  >  v \n",
            " ^  ^  ^  ^  ^  ^  ^  ^  ^  ^  >  v \n",
            " X  C  C  C  C  C  C  C  C  C  C  T \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lk80aT92nIND"
      },
      "source": [
        "### Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8O12IS8nIND",
        "outputId": "a6fda36b-f6b1-44d2-dbd9-fd04332da96a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from submit import submit_sarsa\n",
        "submit_sarsa(rewards_ql, rewards_sarsa, '', '')"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Submitted to Coursera platform. See results on assignment page!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GeAlT655nINE"
      },
      "source": [
        "### More\n",
        "\n",
        "Here are some of the things you can do if you feel like it:\n",
        "\n",
        "* Play with epsilon. See learned how policies change if you set epsilon to higher/lower values (e.g. 0.75).\n",
        "* Expected Value SASRSA for softmax policy:\n",
        "$$ \\pi(a_i|s) = softmax({Q(s,a_i) \\over \\tau}) = {e ^ {Q(s,a_i)/ \\tau}  \\over {\\sum_{a_j}  e ^{Q(s,a_j) / \\tau }}} $$\n",
        "* Implement N-step algorithms and TD($\\lambda$): see [Sutton's book](http://incompleteideas.net/book/bookdraft2018jan1.pdf) chapter 7 and chapter 12.\n",
        "* Use those algorithms to train on CartPole in previous / next assignment for this week."
      ]
    }
  ]
}